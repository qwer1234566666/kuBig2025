{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a07982e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-05 16:13:46--  https://raw.githubusercontent.com/spmallick/learnopencv/refs/heads/master/HandPose/hand/pose_deploy.prototxt\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) 해석 중... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "다음으로 연결 중: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 26452 (26K) [text/plain]\n",
      "저장 위치: ‘pose_deploy.prototxt’\n",
      "\n",
      "pose_deploy.prototx 100%[===================>]  25.83K  --.-KB/s    / 0.001s   \n",
      "\n",
      "2025-06-05 16:13:46 (38.6 MB/s) - ‘pose_deploy.prototxt’ 저장함 [26452/26452]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/spmallick/learnopencv/refs/heads/master/HandPose/hand/pose_deploy.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e215bebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-05 16:13:46--  https://huggingface.co/camenduru/openpose/resolve/5e17f6ad43ab415a0114537541a8d37d2503424f/models/hand/pose_iter_102000.caffemodel\n",
      "huggingface.co (huggingface.co) 해석 중... 3.168.178.31, 3.168.178.101, 3.168.178.58, ...\n",
      "다음으로 연결 중: huggingface.co (huggingface.co)|3.168.178.31|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 302 Found\n",
      "위치: https://cdn-lfs-us-1.hf.co/repos/86/05/8605ab3f750a36cde723f9dfd9634b742108bef91ecb311901ff13749b9dafac/f313aa5ef031ac91606e1a0383daa14be241a6e1a91c1155283dd28503c79c2d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pose_iter_102000.caffemodel%3B+filename%3D%22pose_iter_102000.caffemodel%22%3B&Expires=1749111226&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTExMTIyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg2LzA1Lzg2MDVhYjNmNzUwYTM2Y2RlNzIzZjlkZmQ5NjM0Yjc0MjEwOGJlZjkxZWNiMzExOTAxZmYxMzc0OWI5ZGFmYWMvZjMxM2FhNWVmMDMxYWM5MTYwNmUxYTAzODNkYWExNGJlMjQxYTZlMWE5MWMxMTU1MjgzZGQyODUwM2M3OWMyZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qjHzUsG%7EhGJEzgcbtnEsECKmXmtS43A9Ddq%7ERuTlkSHxTunWAeWd5YQWZXXx9TlpLhm%7EePOstWwjwzSQPtE50yx3dpkSGIW8jOMce%7EHNTb72wV4SAU%7EYfzjbyHvkXKeFUooBcfQ5v8b5kfkCrybMye-WuPXot7ixl9W-IFkK0yQL0ltmlo4X2N83lhQt4Di-aUmu1EABM7hC-YhFv3RcmwECBCPHcDWP2YF6F4aE8Ee1T1L0uIT5CeaTvdgnWBv1MYiBj9g9tR4JpYHgjVESmp8GtWbBFJ9c9simQ-PhYt9nr0kuojmO6u0SQE04SeZqhYSTzelEys7oxx9Lb9ssPQ__&Key-Pair-Id=K24J24Z295AEI9 [따라감]\n",
      "--2025-06-05 16:13:46--  https://cdn-lfs-us-1.hf.co/repos/86/05/8605ab3f750a36cde723f9dfd9634b742108bef91ecb311901ff13749b9dafac/f313aa5ef031ac91606e1a0383daa14be241a6e1a91c1155283dd28503c79c2d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pose_iter_102000.caffemodel%3B+filename%3D%22pose_iter_102000.caffemodel%22%3B&Expires=1749111226&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTExMTIyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg2LzA1Lzg2MDVhYjNmNzUwYTM2Y2RlNzIzZjlkZmQ5NjM0Yjc0MjEwOGJlZjkxZWNiMzExOTAxZmYxMzc0OWI5ZGFmYWMvZjMxM2FhNWVmMDMxYWM5MTYwNmUxYTAzODNkYWExNGJlMjQxYTZlMWE5MWMxMTU1MjgzZGQyODUwM2M3OWMyZD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=qjHzUsG%7EhGJEzgcbtnEsECKmXmtS43A9Ddq%7ERuTlkSHxTunWAeWd5YQWZXXx9TlpLhm%7EePOstWwjwzSQPtE50yx3dpkSGIW8jOMce%7EHNTb72wV4SAU%7EYfzjbyHvkXKeFUooBcfQ5v8b5kfkCrybMye-WuPXot7ixl9W-IFkK0yQL0ltmlo4X2N83lhQt4Di-aUmu1EABM7hC-YhFv3RcmwECBCPHcDWP2YF6F4aE8Ee1T1L0uIT5CeaTvdgnWBv1MYiBj9g9tR4JpYHgjVESmp8GtWbBFJ9c9simQ-PhYt9nr0kuojmO6u0SQE04SeZqhYSTzelEys7oxx9Lb9ssPQ__&Key-Pair-Id=K24J24Z295AEI9\n",
      "cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co) 해석 중... 3.168.178.111, 3.168.178.50, 3.168.178.65, ...\n",
      "다음으로 연결 중: cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.168.178.111|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 147344024 (141M) [binary/octet-stream]\n",
      "저장 위치: ‘pose_iter_102000.caffemodel.1’\n",
      "\n",
      "pose_iter_102000.ca 100%[===================>] 140.52M  88.3MB/s    / 1.6s     \n",
      "\n",
      "2025-06-05 16:13:48 (88.3 MB/s) - ‘pose_iter_102000.caffemodel.1’ 저장함 [147344024/147344024]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/camenduru/openpose/resolve/5e17f6ad43ab415a0114537541a8d37d2503424f/models/hand/pose_iter_102000.caffemodel\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f325ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-05 16:14:53--  https://raw.githubusercontent.com/spmallick/learnopencv/refs/heads/master/HandPose/right-frontal.jpg\n",
      "raw.githubusercontent.com (raw.githubusercontent.com) 해석 중... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "다음으로 연결 중: raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 223613 (218K) [image/jpeg]\n",
      "저장 위치: ‘right-frontal.jpg’\n",
      "\n",
      "right-frontal.jpg   100%[===================>] 218.37K  --.-KB/s    / 0.02s    \n",
      "\n",
      "2025-06-05 16:14:53 (9.54 MB/s) - ‘right-frontal.jpg’ 저장함 [223613/223613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/spmallick/learnopencv/refs/heads/master/HandPose/right-frontal.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f6ceffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) ./modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/home/yjh/kubig2025/opencv/part6/pose_deploy.prototxt\" in function 'ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 30\u001b[0m\n\u001b[1;32m      7\u001b[0m nPoints \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22\u001b[39m\n\u001b[1;32m      8\u001b[0m POSE_PAIRS \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     10\u001b[0m     [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     [\u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[1;32m     29\u001b[0m ]\n\u001b[0;32m---> 30\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadNetFromCaffe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotoFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweightsFile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) ./modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"/home/yjh/kubig2025/opencv/part6/pose_deploy.prototxt\" in function 'ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "protoFile = \"/home/yjh/kubig2025/opencv/part6/pose_deploy.prototxt\"\n",
    "weightsFile = \"/home/yjh/kubig2025/opencv/part6/pose_iter_102000.caffemodel\"\n",
    "nPoints = 22\n",
    "POSE_PAIRS = [\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 4],\n",
    "    [0, 5],\n",
    "    [5, 6],\n",
    "    [6, 7],\n",
    "    [7, 8],\n",
    "    [0, 9],\n",
    "    [9, 10],\n",
    "    [10, 11],\n",
    "    [11, 12],\n",
    "    [0, 13],\n",
    "    [13, 14],\n",
    "    [14, 15],\n",
    "    [15, 16],\n",
    "    [0, 17],\n",
    "    [17, 18],\n",
    "    [18, 19],\n",
    "    [19, 20],\n",
    "]\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb2ac696",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m inWidth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(((aspect_ratio \u001b[38;5;241m*\u001b[39m inHeight) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     13\u001b[0m inpBlob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(\n\u001b[1;32m     14\u001b[0m     frame, \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m, (inWidth, inHeight), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39msetInput(inpBlob)\n\u001b[1;32m     19\u001b[0m output \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mforward()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime taken by network : \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "frame = cv2.imread(\"right-frontal.jpg\")\n",
    "frameCopy = np.copy(frame)\n",
    "frameWidth = frame.shape[1]\n",
    "frameHeight = frame.shape[0]\n",
    "aspect_ratio = frameWidth / frameHeight\n",
    "threshold = 0.1\n",
    "\n",
    "t = time.time()\n",
    "# input image dimensions for the network\n",
    "inHeight = 368\n",
    "# inWidth = 368\n",
    "inWidth = int(((aspect_ratio * inHeight) * 8) // 8)\n",
    "inpBlob = cv2.dnn.blobFromImage(\n",
    "    frame, 1.0 / 255, (inWidth, inHeight), (0, 0, 0), swapRB=False, crop=False\n",
    ")\n",
    "\n",
    "net.setInput(inpBlob)\n",
    "\n",
    "output = net.forward()\n",
    "print(\"time taken by network : {:.3f}\".format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0fa13509",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m points \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nPoints):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# confidence map of corresponding body's part.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     probMap \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m[\u001b[38;5;241m0\u001b[39m, i, :, :]\n\u001b[1;32m      9\u001b[0m     probMap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(probMap, (frameWidth, frameHeight))\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Find global maxima of the probMap.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Empty list to store the detected keypoints\n",
    "points = []\n",
    "\n",
    "for i in range(nPoints):\n",
    "    # confidence map of corresponding body's part.\n",
    "    probMap = output[0, i, :, :]\n",
    "    probMap = cv2.resize(probMap, (frameWidth, frameHeight))\n",
    "\n",
    "    # Find global maxima of the probMap.\n",
    "    minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "    if prob > threshold:\n",
    "        cv2.circle(\n",
    "            frameCopy,\n",
    "            (int(point[0]), int(point[1])),\n",
    "            3,\n",
    "            (0, 255, 255),\n",
    "            thickness=-1,\n",
    "            lineType=cv2.FILLED,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frameCopy,\n",
    "            \"{}\".format(i),\n",
    "            (int(point[0]), int(point[1])),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (0, 0, 255),\n",
    "            2,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Add the point to the list if the probability is greater than the threshold\n",
    "        points.append((int(point[0]), int(point[1])))\n",
    "    else:\n",
    "        points.append(None)\n",
    "\n",
    "# Draw Skeleton\n",
    "for pair in POSE_PAIRS:\n",
    "    partA = pair[0]\n",
    "    partB = pair[1]\n",
    "\n",
    "    if points[partA] and points[partB]:\n",
    "        cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n",
    "        cv2.circle(\n",
    "            frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED\n",
    "        )\n",
    "        cv2.circle(\n",
    "            frame, points[partB], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED\n",
    "        )\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10, 10])\n",
    "plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB))\n",
    "plt.figure(figsize=[10, 10])\n",
    "plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "cv2.imwrite(\"Output-Keypoints.jpg\", frameCopy)\n",
    "cv2.imwrite(\"Output-Skeleton.jpg\", frame)\n",
    "\n",
    "print(\"Total time taken : {:.3f}\".format(time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
